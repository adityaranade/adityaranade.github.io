---
title: "Starbucks food nutritional information"
subtitle: "We all like starbucks food, but what about the nutritional value of them?"
author: "Aditya Ranade"
highlight-style:
            light: github
date: "2025-05-01"
categories: [analysis]
image: "./starbucks_food.jpg"
---

::: {style="text-align: justify"}
Starbucks is one of the most valued coffee chain in the world. A lot of people like to consume the food available at starbucks. But how good are they in terms of the nutritional value?
:::

::: {style="text-align: justify"}
I found this dataset on Kaggle which gives the nutritional information about their food products. In my precious post, I built a multiple linear regression model to predict the calories in beverage based on the nutritional contents of the beverage. Now we will try to do the same for the food products. 

First, we look at the exploratory data analysis and later try some simple regression models. First let us access and process the data through R.
:::

```{r}
#| label: load-packages
#| echo: true
#| warning: false
#| include: true

# Load the packages
library(reshape2)
library(ggplot2)
library(ggh4x)
library(ggcorrplot)
library(car) # to calculate the VIF values
library(GGally) # for pairs plot using ggplot framework
```

```{r}
#| label: data_processing1
#| echo: true
#| warning: false
#| include: true

# Get starbucks data from github repo
path <- "https://raw.githubusercontent.com/adityaranade/starbucks/refs/heads/main/data/starbucks-menu-nutrition-food.csv"
data0 <- read.csv(path, header = TRUE)

# Data processing
# change the column names
colnames(data0) <- c("name", "calories", "fat", 
                     "carbs", "fiber","protein")

# Check the first 6 rows of the dataset
data0 |> head()

# Check the type of data
data0 |> str()

```

::: {style="text-align: justify"}
The data from second column should be numeric but shows as character. So we first convert it into numeric form and also exclude the rows with missing information
:::

```{r}
#| label: data_processing2
#| echo: true
#| warning: false
#| include: true

# convert the data to numeric second row onwards
data0$calories <- as.numeric(data0$calories)
data0$fat <- as.numeric(data0$fat)
data0$carbs <- as.numeric(data0$carbs)
data0$fiber <- as.numeric(data0$fiber)
data0$protein <- as.numeric(data0$protein)

# Check the type of data again
data0 |> str()

# Check the rows which do not have any entries
ind.na <- which(is.na(data0[,2]))
length(ind.na) # 0 NA values
data <- data0
```

::: {style="text-align: justify"}
Now that we have the data ready, let us look at the histogram each of the variables namely calories, fat, carbs, fiber, protein and sodium
:::

```{r}
#| label: EDA
#| echo: true
#| warning: false
#| include: true

# Data for histogram
melted_data <- melt(data, id.vars="name")

# Plot the histogram of all the variables
ggplot(melted_data,aes(value))+
  geom_histogram(bins = 20)+
  facet_grid2(~variable, scales="free")
```

::: {style="text-align: justify"}
Histogram does not give much information. Let us look at the correlation plot to get an idea of how the variables are correlated with each other.
:::

```{r}
#| label: correlation_plot
#| echo: true
#| warning: false
#| include: true

# correlation plot of all the variables
corr <- round(cor(data[,-1]), 1)
p.mat <- cor_pmat(mtcars) # correlation p-value
# Barring the no significant coefficient
ggcorrplot(corr, hc.order = TRUE,
           type = "lower", p.mat = p.mat)
# All positive correlation
```

::: {style="text-align: justify"}
All the variables are positively correlated (which indicates when one variable increases, the other variable will increase as well. ) which is not a surprising. Most important part is the correlation of calories with all the other variables are considerably high. Next we look at the pairs plot which will show the bivariate scatter plots as well as the correlation between each variables.
:::

```{r}
#| label: pairplots
#| echo: true
#| warning: false
#| include: true

ggpairs(data,columns = 2:ncol(data),
        lower = list(continuous = "smooth"))

```

::: {style="text-align: justify"}
Most of the bivariate scatter plots indicate a linear relationship between the variables. The most important result according to us is the relationship between calories with all the other variables. We can now use the dataset for predictions where we try to predict the calories based on the fat, carb, fiber and protein content using multiple linear regression.
:::

```{r}
#| label: MLR_raw
#| echo: true
#| warning: false
#| include: true

# split the data into training and testing data
seed <- 23
set.seed(seed)

ind <- sample(floor(0.8*nrow(data)),
              replace = FALSE)

# Training dataset
data_train <- data[ind,-1]
# Testing dataset
data_test <- data[-ind,-1]

# Multiple linear regression using raw data
model <- lm(calories ~ fat + carbs + fiber + protein , data = data_train)
summary(model)

# Prediction on the testing dataset
y_pred <- predict(model, data_test)

# Create a observed vs. predicted plot
ggplot(NULL,aes(y_pred,data_test$calories))+geom_point()+
  labs(y = "Observed", x="Predicted")+geom_abline()

# Calculate RMSE
rmse <- (y_pred-data_test$calories)^2 |> sum() |> sqrt()
rmse

# Check the variance inflation factor
vif_values <- vif(model)
vif_values
```

::: {style="text-align: justify"}
The model is decent with RMSE 70.17 and the observed vs. predicted plot also looks decent with all the points just around the line. The variation inflation factor (VIF) is also below 2 for all the variables. We will look at the residual plots to check if all the assumptions of multiple linear regression are satisfied.
:::

```{r}
#| label: assumption
#| echo: true
#| warning: false
#| include: true

# Check the assumptions of the regression model
par(mfrow = c(2, 2))
plot(model)
```

::: {style="text-align: justify"}
Nothing in the residual plots indicate a cause of concern regarding the model.
:::
