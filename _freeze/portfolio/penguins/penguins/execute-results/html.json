{
  "hash": "c0901329dc58bbc8f530913d1076328a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Identify Penguin species\"\nsubtitle: \"Identify penguin species using multinomial Logistic Regression\"\nauthor: \"Aditya Ranade\"\nhighlight-style:\n  light: github\ndate: \"2025-04-29\"\ncategories: [analysis, R]\nimage: \"./penguin.jpg\"\n---\n\n\n\n\n\n::: {style=\"text-align: justify\"}\nI found this [dataset](https://archive.ics.uci.edu/dataset/690/palmer+penguins-3) on UCI machine learning repository which gives the dataset for 3 penguin species in the islands of Palmer Archipelago, Antarctica. It has some basic measurements on the penguins of the 3 species.\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reshape2)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(ggh4x)\nlibrary(GGally)\nlibrary(naivebayes)\nlibrary(caret)\nlibrary(e1071)\n\n# Data is available in the palmer penguins package in R\nlibrary(palmerpenguins)\n\n\n# Data processing\ndata0 <- penguins\nhead(data0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  <fct>   <fct>              <dbl>         <dbl>             <int>       <int>\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex <fct>, year <int>\n```\n\n\n:::\n\n```{.r .cell-code}\ndata0 |> str()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check the rows which do not have any entries\nsum(is.na(data0)) # 19 NA values\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 19\n```\n\n\n:::\n\n```{.r .cell-code}\n# exclude the rows which has NA in them\ndata00 <- na.omit(data0)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Pairs plot between the explanatory variables to \n# check correlation between each pair of the variables\nggpairs(data00[,-c(2,8)])\n```\n\n::: {.cell-output-display}\n![](penguins_files/figure-html/EDA0-1.png){width=672}\n:::\n:::\n\n\n\n\n\n::: {style=\"text-align: justify\"}\nIt is not unexpected to see multicollinearity in the data for the continuous variables since they are body measurements for the penguins.\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Histogram based on species\nmelted_data <- melt(data00[,c(1,3,4,5,6)], id=\"species\")\n\n# Plot the histogram of all the variables\nggplot(melted_data,aes(value))+\n  geom_histogram(aes(),bins = 30)+\n  facet_grid2(species~variable, scales=\"free\")+theme_bw()\n```\n\n::: {.cell-output-display}\n![](penguins_files/figure-html/EDA1-1.png){width=1344}\n:::\n\n```{.r .cell-code}\n# Histogram based on sex\nmelted_data2 <- melt(data00[,c(3,4,5,6,7)], id=\"sex\")\n\n# Plot the histogram of all the variables\nggplot(melted_data2,aes(value))+\n  geom_histogram(aes(),bins = 30)+\n  facet_grid2(sex~variable, scales=\"free\")+theme_bw()\n```\n\n::: {.cell-output-display}\n![](penguins_files/figure-html/EDA1-2.png){width=1344}\n:::\n:::\n\n\n\n\n\n::: {style=\"text-align: justify\"}\nThere is a distinct difference in the histogram of all the variables based on the species and sex. We will look to build a naive Bayes classification model to identify the species of penguins. First let us split the data into training and testing set.\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select variables to be used in the model\ndata <- data00 %>% dplyr::select(species,bill_length_mm,bill_depth_mm,\n                                 flipper_length_mm,body_mass_g)\n\ndata1 <- subset(data, species == \"Adelie\")\ndata2 <- subset(data, species == \"Chinstrap\")\ndata3 <- subset(data, species == \"Gentoo\")\n\n# split the data into training (70%) and testing (30%) data\nseed <- 33\nset.seed(seed)\nind1 <- sample(floor(0.7*nrow(data1)),\n              replace = FALSE)\n\nind2 <- sample(floor(0.7*nrow(data2)),\n               replace = FALSE)\n\nind3 <- sample(floor(0.7*nrow(data3)),\n               replace = FALSE)\n\n\n# Training dataset\ndata_train <- rbind(data1[ind1,],data2[ind2,],data3[ind3,])\ndata_train |> count(species)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n  species       n\n  <fct>     <int>\n1 Adelie      102\n2 Chinstrap    47\n3 Gentoo       83\n```\n\n\n:::\n\n```{.r .cell-code}\n# Testing dataset\ndata_test <- rbind(data1[-ind1,],data2[-ind2,],data3[-ind3,])\ndata_test |> count(species)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n  species       n\n  <fct>     <int>\n1 Adelie       44\n2 Chinstrap    21\n3 Gentoo       36\n```\n\n\n:::\n:::\n\n\n\n\n\n::: {style=\"text-align: justify\"}\nWe now build a naive Bayes classification model to identify the species of Penguins.\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2 <- naiveBayes(species ~ ., data = data_train) \nmodel2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nNaive Bayes Classifier for Discrete Predictors\n\nCall:\nnaiveBayes.default(x = X, y = Y, laplace = laplace)\n\nA-priori probabilities:\nY\n   Adelie Chinstrap    Gentoo \n0.4396552 0.2025862 0.3577586 \n\nConditional probabilities:\n           bill_length_mm\nY               [,1]     [,2]\n  Adelie    38.69706 2.661439\n  Chinstrap 48.83404 3.409531\n  Gentoo    47.11807 2.936862\n\n           bill_depth_mm\nY               [,1]      [,2]\n  Adelie    18.49216 1.2083608\n  Chinstrap 18.44681 1.1321106\n  Gentoo    14.83855 0.9528943\n\n           flipper_length_mm\nY               [,1]     [,2]\n  Adelie    189.2255 6.494334\n  Chinstrap 194.6596 6.885008\n  Gentoo    216.5422 6.210340\n\n           body_mass_g\nY               [,1]     [,2]\n  Adelie    3729.657 458.5914\n  Chinstrap 3744.149 417.3289\n  Gentoo    5053.614 526.8135\n```\n\n\n:::\n\n```{.r .cell-code}\ny_pred2 <- predict(model2, newdata = data_test)\nconf_table2 <- table(data_test$species, y_pred2)\nconfusionMatrix(conf_table2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n           y_pred2\n            Adelie Chinstrap Gentoo\n  Adelie        42         2      0\n  Chinstrap      1        20      0\n  Gentoo         0         0     36\n\nOverall Statistics\n                                          \n               Accuracy : 0.9703          \n                 95% CI : (0.9156, 0.9938)\n    No Information Rate : 0.4257          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.9537          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: Adelie Class: Chinstrap Class: Gentoo\nSensitivity                 0.9767           0.9091        1.0000\nSpecificity                 0.9655           0.9873        1.0000\nPos Pred Value              0.9545           0.9524        1.0000\nNeg Pred Value              0.9825           0.9750        1.0000\nPrevalence                  0.4257           0.2178        0.3564\nDetection Rate              0.4158           0.1980        0.3564\nDetection Prevalence        0.4356           0.2079        0.3564\nBalanced Accuracy           0.9711           0.9482        1.0000\n```\n\n\n:::\n\n```{.r .cell-code}\n# Misclassification\n1 - sum(diag(conf_table2)) / sum(conf_table2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.02970297\n```\n\n\n:::\n:::\n\n\n\n\n\n::: {style=\"text-align: justify\"}\nThe misclassification rate of the model on test dataset is about 3% which is not bad. We will now try to code the model without using any package.\n:::\n",
    "supporting": [
      "penguins_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}