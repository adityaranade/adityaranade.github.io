{
  "hash": "aee5ad3a75f6c3942af455c7f716bfd0",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Predicting Gallstone Disease\"\nsubtitle: \"Comparing AI methods to predict gallstone disease\"\nauthor: \"Aditya Ranade\"\nhighlight-style: github-light\ndate: \"2025-05-07\"\ncategories: [AI, analysis, python, R]\nimage: \"./gallbladder.png\"\njupyter: python3\n---\n\n\n\n\n\n::: {style=\"text-align: justify\"}\nI found this [dataset](https://archive.ics.uci.edu/dataset/1150/gallstone-1) on UCI machine learning repository which gives gallstone disease identification data. First, we look at the exploratory data analysis and later try to build predictive models like logistic regression, support vector classifier and k nearest neighbour model. First let us access and process the data through python.\n:::\n\n::: {#cell-load-packages .cell execution_count=1}\n``` {.python .cell-code}\n# Load Libraries\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom plotnine import *\nimport numpy as np # linear algebra\n# import statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport openpyxl\n\n# Get gallstone data from github repo\npath = \"https://raw.githubusercontent.com/adityaranade/portfolio/refs/heads/main/gallstone/gallstone_dataset.csv\"\ndf0=pd.read_csv(path)\n\ndf0.head()\n```\n\n::: {#load-packages .cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gallstone Status</th>\n      <th>Age</th>\n      <th>Gender</th>\n      <th>Comorbidity</th>\n      <th>Coronary Artery Disease (CAD)</th>\n      <th>Hypothyroidism</th>\n      <th>Hyperlipidemia</th>\n      <th>Diabetes Mellitus (DM)</th>\n      <th>Height</th>\n      <th>Weight</th>\n      <th>...</th>\n      <th>High Density Lipoprotein (HDL)</th>\n      <th>Triglyceride</th>\n      <th>Aspartat Aminotransferaz (AST)</th>\n      <th>Alanin Aminotransferaz (ALT)</th>\n      <th>Alkaline Phosphatase (ALP)</th>\n      <th>Creatinine</th>\n      <th>Glomerular Filtration Rate (GFR)</th>\n      <th>C-Reactive Protein (CRP)</th>\n      <th>Hemoglobin (HGB)</th>\n      <th>Vitamin D</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>50</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>185</td>\n      <td>92.8</td>\n      <td>...</td>\n      <td>40.0</td>\n      <td>134.0</td>\n      <td>20.0</td>\n      <td>22.0</td>\n      <td>87.0</td>\n      <td>0.82</td>\n      <td>112.47</td>\n      <td>0.0</td>\n      <td>16.0</td>\n      <td>33.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>47</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>176</td>\n      <td>94.5</td>\n      <td>...</td>\n      <td>43.0</td>\n      <td>103.0</td>\n      <td>14.0</td>\n      <td>13.0</td>\n      <td>46.0</td>\n      <td>0.87</td>\n      <td>107.10</td>\n      <td>0.0</td>\n      <td>14.4</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>61</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>171</td>\n      <td>91.1</td>\n      <td>...</td>\n      <td>43.0</td>\n      <td>69.0</td>\n      <td>18.0</td>\n      <td>14.0</td>\n      <td>66.0</td>\n      <td>1.25</td>\n      <td>65.51</td>\n      <td>0.0</td>\n      <td>16.2</td>\n      <td>30.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>41</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>168</td>\n      <td>67.7</td>\n      <td>...</td>\n      <td>59.0</td>\n      <td>53.0</td>\n      <td>20.0</td>\n      <td>12.0</td>\n      <td>34.0</td>\n      <td>1.02</td>\n      <td>94.10</td>\n      <td>0.0</td>\n      <td>15.4</td>\n      <td>35.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>178</td>\n      <td>89.6</td>\n      <td>...</td>\n      <td>30.0</td>\n      <td>326.0</td>\n      <td>27.0</td>\n      <td>54.0</td>\n      <td>71.0</td>\n      <td>0.82</td>\n      <td>112.47</td>\n      <td>0.0</td>\n      <td>16.8</td>\n      <td>40.6</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 39 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#data_processing1 .cell execution_count=2}\n``` {.python .cell-code}\n# select specific columns\ndf = df0[[\"Gallstone Status\",\"Vitamin D\",\"Total Body Water (TBW)\",\"Lean Mass (LM) (%)\",\"C-Reactive Protein (CRP)\"]]\n# df.head()\n```\n:::\n\n\n::: {#data_processing2 .cell execution_count=3}\n``` {.python .cell-code}\n# Use melt function for the histograms\ndf2 = pd.melt(df, id_vars=['Gallstone Status'])\n# df2.head()\n```\n:::\n\n\n::: {style=\"text-align: justify\"}\nNow that we have the data ready, let us look at the histogram of each variables namely calories, fat, carbs, fiber, protein and sodium\n:::\n\n::: {#cell-EDA .cell execution_count=4}\n``` {.python .cell-code}\np = (\nggplot(df2, aes(\"value\"))\n+ geom_histogram(bins=20)\n+ facet_grid(\"Gallstone Status ~ variable\", scales=\"free\")+\n  theme_bw()\n)\n\np.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/eda-output-1.png){#eda width=672 height=480}\n:::\n:::\n\n\nThe histogram of each of the variables do not show any problems as all the plots look decent. We will look at the correlation plot.\n\n::: {#cell-EDA2 .cell execution_count=5}\n``` {.python .cell-code}\n# Correlation plot\nplt.figure(figsize=(15,10))\nsns.heatmap(df.iloc[:,1:].corr(),annot=True)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/eda2-output-1.png){#eda2}\n:::\n:::\n\n\n::: {style=\"text-align: justify\"}\nCorrelation plot indicates weak association between all the variables which indicates there might not be severe multicolinearity. It does not warrant any cause of concern. Now we will look at the pairs plot which will show the pairwise relationship.\n:::\n\n::: {#cell-EDA3 .cell execution_count=6}\n``` {.python .cell-code}\n# Pairs plot\ng = sns.PairGrid(df.iloc[:,1:])\ng.map_diag(sns.histplot)\ng.map_upper(sns.kdeplot)\ng.map_lower(sns.scatterplot)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/eda3-output-1.png){#eda3}\n:::\n:::\n\n\n::: {style=\"text-align: justify\"}\nThe scatterplots of each variable with which can be seen in the lower triangular plots. No strong association between any two variables. We will try to run different models like logistic regression, k nearest neighbours and support vector classification model on the data. First we will split the data into training (70%) and testing set (30%) and standardize the data.\n:::\n\n::: {#data_split .cell execution_count=7}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Split data into training and testing set\ndf_train0, df_test0 = train_test_split(df, test_size=0.3, random_state=23)\n\n# Scale (exclude first column)\nscaler = StandardScaler()\n\ndf_train = df_train0.copy()\ndf_test = df_test0.copy()\n\ndf_train.iloc[:, 1:] = scaler.fit_transform(df_train0.iloc[:, 1:])\ndf_test.iloc[:, 1:] = scaler.transform(df_test0.iloc[:, 1:])\n\nX_train = df_train.iloc[:,1:]\ny_train = df_train.iloc[:,0]\nX_test = df_test.iloc[:,1:]\ny_test = df_test.iloc[:,0]\n```\n:::\n\n\n::: {style=\"text-align: justify\"}\nNow we will run a logistic regression model first.\n:::\n\n::: {#logistic_model1 .cell execution_count=8}\n``` {.python .cell-code}\n# Create logistic regression model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Predictions\ny_pred_logistic = model.predict(X_test)\n\n# Evaluation\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_logistic))\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_logistic))\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_logistic))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix:\n [[36 15]\n [11 34]]\nAccuracy: 0.7291666666666666\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.77      0.71      0.73        51\n           1       0.69      0.76      0.72        45\n\n    accuracy                           0.73        96\n   macro avg       0.73      0.73      0.73        96\nweighted avg       0.73      0.73      0.73        96\n\n```\n:::\n:::\n\n\n::: {#cell-logistic_model2 .cell execution_count=9}\n``` {.python .cell-code}\nfrom sklearn.metrics import roc_auc_score, roc_curve\n\ny_prob = model.predict_proba(X_test)[:, 1]  # probability of positive class\nauc = roc_auc_score(y_test, y_prob)\nprint(\"AUC:\", auc)\n\nfpr, tpr, _ = roc_curve(y_test, y_prob)\nplt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\nplt.plot([0, 1], [0, 1], linestyle=\"--\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAUC: 0.8113289760348584\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/logistic_model2-output-2.png){#logistic_model2}\n:::\n:::\n\n\n::: {style=\"text-align: justify\"}\nNext, we will run a k nearest neighbour model.\n:::\n\n::: {#knn_model .cell execution_count=10}\n``` {.python .cell-code}\n# KNN model\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n\nfrom sklearn.model_selection import cross_val_score\nk_values = range(1, 11)\nscores = []\n\nfor k in k_values:\n  knn = KNeighborsClassifier(n_neighbors=k)\n  score = cross_val_score(knn, X_train, y_train, cv=5).mean()\n  scores.append(score)\n\nbest_k = k_values[np.argmax(scores)]\nprint(\"Best k:\", best_k)\n\n# Create KNN model using the best k\nknn = KNeighborsClassifier(n_neighbors=best_k)\nknn.fit(X_train, y_train)\n\n# Predictions\ny_pred_knn = knn.predict(X_test)\n\n# Accuracy\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_knn))\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_knn))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBest k: 7\nConfusion Matrix:\n [[38 13]\n [12 33]]\nAccuracy: 0.7395833333333334\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.76      0.75      0.75        51\n           1       0.72      0.73      0.73        45\n\n    accuracy                           0.74        96\n   macro avg       0.74      0.74      0.74        96\nweighted avg       0.74      0.74      0.74        96\n\n```\n:::\n:::\n\n\n::: {style=\"text-align: justify\"}\nNext, we will run a support vector classification model.\n:::\n\n::: {#svc_model .cell execution_count=11}\n``` {.python .cell-code}\n# svc model\nfrom sklearn.svm import SVC\n# Identify the best parameter through CV\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n'C': [0.1, 1, 10],\n'gamma': ['scale', 0.01, 0.1, 1],\n'kernel': ['rbf', 'linear']\n}\n\ngrid = GridSearchCV(SVC(), param_grid, refit=True, cv=5)\ngrid.fit(X_train, y_train)\n\nprint(\"Best parameters:\", grid.best_params_)\n\n# Create SVM model using the best parameters\nsvm_model = SVC(kernel='rbf', C=10, gamma=0.01)\nsvm_model.fit(X_train, y_train)\n\n# Predictions\ny_pred_svm = svm_model.predict(X_test)\n\n# Evaluation\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_svm))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBest parameters: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\nConfusion Matrix:\n [[38 13]\n [14 31]]\nAccuracy: 0.71875\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.73      0.75      0.74        51\n           1       0.70      0.69      0.70        45\n\n    accuracy                           0.72        96\n   macro avg       0.72      0.72      0.72        96\nweighted avg       0.72      0.72      0.72        96\n\n```\n:::\n:::\n\n\n::: {#combine_results .cell execution_count=12}\n``` {.python .cell-code}\n# Combine the results of all the models.\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Store all models\nmodels = {\n    \"Logistic Regression\": y_pred_logistic,\n    \"KNN\": y_pred_knn,\n    \"SVM\": y_pred_knn\n}\n\n# Calculate metrics for each model\nresults = []\nfor name, y_pred in models.items():\n    results.append({\n        \"Model\": name,\n        \"Accuracy\": round(accuracy_score(y_test, y_pred),4),\n        \"Precision\": round(precision_score(y_test, y_pred),4),\n        \"Recall\": round(recall_score(y_test, y_pred),4),\n        \"F1 Score\": round(f1_score(y_test, y_pred),4)\n    })\n\n# Create DataFrame\nresults_df = pd.DataFrame(results)\nprint(results_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 Model  Accuracy  Precision  Recall  F1 Score\n0  Logistic Regression    0.7292     0.6939  0.7556    0.7234\n1                  KNN    0.7396     0.7174  0.7333    0.7253\n2                  SVM    0.7396     0.7174  0.7333    0.7253\n```\n:::\n:::\n\n\n::: {style=\"text-align: justify\"}\nThe combined evaluation metrics can be seen in the table above. It seems the k nearest neighbor model has the highest accuracy. However, the accuracy for the logistic regression and support vector machine models is not too bad. The R code for the analysis can be found [here](https://raw.githubusercontent.com/adityaranade/portfolio/refs/heads/main/gallstone/gallstone.R)\n:::\n\n",
    "supporting": [
      "index_files\\figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}