{
  "hash": "8d53ce8b47db16c568dcc721a26330ca",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Credit approval\"\nsubtitle: \"Predicting credit approval using binary logistic regression model\"\nauthor: \"Aditya Ranade\"\nhighlight-style:\n            light: github\ndate: \"2025-03-14\"\ncategories: [analysis, R]\nimage: \"./credit.jpg\"\n---\n\n\n\n::: {style=\"text-align: justify\"}\nI found this [dataset](https://archive.ics.uci.edu/dataset/27/credit+approval) on UCI machine learning repository which gives the credit approval dataset for a Japanese credit agency. The variable names have been changed to generic names and the factor levels have been changed to general symbols. We will look to build a logistic regression based on the data and try to predict if credit is given or not.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reshape2)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(ggh4x)\nlibrary(cmdstanr)\nlibrary(bayesplot)\nlibrary(rstanarm)\n\n# Get data from github repo\npath <- \"https://raw.githubusercontent.com/adityaranade/portfolio/refs/heads/main/credit/data/crx.data\"\ndata0 <- read.table(path, sep=\",\")\n\n# Data processing\nhead(data0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  V1    V2    V3 V4 V5 V6 V7   V8 V9 V10 V11 V12 V13   V14 V15 V16\n1  b 30.83 0.000  u  g  w  v 1.25  t   t   1   f   g 00202   0   +\n2  a 58.67 4.460  u  g  q  h 3.04  t   t   6   f   g 00043 560   +\n3  a 24.50 0.500  u  g  q  h 1.50  t   f   0   f   g 00280 824   +\n4  b 27.83 1.540  u  g  w  v 3.75  t   t   5   t   g 00100   3   +\n5  b 20.17 5.625  u  g  w  v 1.71  t   f   0   f   s 00120   0   +\n6  b 32.08 4.000  u  g  m  v 2.50  t   f   0   t   g 00360   0   +\n```\n\n\n:::\n:::\n\n\n\n\n::: {style=\"text-align: justify\"}\nIn this case, we will restrict ourselves to continuous response variables, namely V2, V3, V8, V11 and V15.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# V16 is the response +/- so convert the response to 0 and 1\ndata0$response <- ifelse(data0$V16 ==\"+\",1,ifelse(data0$V16 ==\"-\",0,NA))\ndata0$decision <- ifelse(data0$V16 ==\"+\",\"credit_granted\",ifelse(data0$V16 ==\"-\",\"credit_not_granted\",NA)) \n\n# Check the first 6 rows of the dataset\ndata0 |> head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  V1    V2    V3 V4 V5 V6 V7   V8 V9 V10 V11 V12 V13   V14 V15 V16 response\n1  b 30.83 0.000  u  g  w  v 1.25  t   t   1   f   g 00202   0   +        1\n2  a 58.67 4.460  u  g  q  h 3.04  t   t   6   f   g 00043 560   +        1\n3  a 24.50 0.500  u  g  q  h 1.50  t   f   0   f   g 00280 824   +        1\n4  b 27.83 1.540  u  g  w  v 3.75  t   t   5   t   g 00100   3   +        1\n5  b 20.17 5.625  u  g  w  v 1.71  t   f   0   f   s 00120   0   +        1\n6  b 32.08 4.000  u  g  m  v 2.50  t   f   0   t   g 00360   0   +        1\n        decision\n1 credit_granted\n2 credit_granted\n3 credit_granted\n4 credit_granted\n5 credit_granted\n6 credit_granted\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check the type of data\ndata0 |> str()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t690 obs. of  18 variables:\n $ V1      : chr  \"b\" \"a\" \"a\" \"b\" ...\n $ V2      : chr  \"30.83\" \"58.67\" \"24.50\" \"27.83\" ...\n $ V3      : num  0 4.46 0.5 1.54 5.62 ...\n $ V4      : chr  \"u\" \"u\" \"u\" \"u\" ...\n $ V5      : chr  \"g\" \"g\" \"g\" \"g\" ...\n $ V6      : chr  \"w\" \"q\" \"q\" \"w\" ...\n $ V7      : chr  \"v\" \"h\" \"h\" \"v\" ...\n $ V8      : num  1.25 3.04 1.5 3.75 1.71 ...\n $ V9      : chr  \"t\" \"t\" \"t\" \"t\" ...\n $ V10     : chr  \"t\" \"t\" \"f\" \"t\" ...\n $ V11     : int  1 6 0 5 0 0 0 0 0 0 ...\n $ V12     : chr  \"f\" \"f\" \"f\" \"t\" ...\n $ V13     : chr  \"g\" \"g\" \"g\" \"g\" ...\n $ V14     : chr  \"00202\" \"00043\" \"00280\" \"00100\" ...\n $ V15     : int  0 560 824 3 0 0 31285 1349 314 1442 ...\n $ V16     : chr  \"+\" \"+\" \"+\" \"+\" ...\n $ response: num  1 1 1 1 1 1 1 1 1 1 ...\n $ decision: chr  \"credit_granted\" \"credit_granted\" \"credit_granted\" \"credit_granted\" ...\n```\n\n\n:::\n\n```{.r .cell-code}\n# Convert the data into appropriate factors or numbers\ndata0$V2 <- data0$V2 |> as.numeric()\ndata0$V3 <- data0$V3 |> as.numeric()\ndata0$V8 <- data0$V8 |> as.numeric()\ndata0$V11 <- data0$V11 |> as.numeric()\ndata0$V15 <- data0$V15 |> as.numeric()\n\n# Combine only numerical data along with the response\ndata1 <- data0 |> dplyr::select(response,V2,V3,V8,V11,V15)\ndata2 <- data0 |> dplyr::select(decision,V2,V3,V8,V11,V15)\n# data1 |> str()\n\n# Check the number of NA values\nsum(is.na(data1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 12\n```\n\n\n:::\n\n```{.r .cell-code}\n# Exclude the rows which has NA values\ndata10 <- na.omit(data1)\n```\n:::\n\n\n\n::: {style=\"text-align: justify\"}\nWe look at the distribution of the continuous data variables based on if decision variable (credit given / credit not given)\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Data for histogram\nmelted_data <- melt(na.omit(data2), id=\"decision\")\n\n# Plot the histogram of all the variables\nggplot(melted_data,aes(value))+\n  geom_histogram(aes(),bins = 30)+\n  # geom_histogram(aes(y = after_stat(density)),bins = 20)+\n  facet_grid2(decision~variable, scales=\"free\")+theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/EDA1-1.png){width=1344}\n:::\n:::\n\n\n\n\n::: {style=\"text-align: justify\"}\nThe distribution of the first two variables (V2 and V3) is similar across the decision. So we will exclude these two variables from the model as it is unlikely to have an impact on the decision.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Exclude V3 and V8 variables\ndata <- data10[,-(2:3)]\n\n# split the data into training and testing data\nseed <- 55\nset.seed(seed)\nind <- sample(floor(0.75*nrow(data)),\n              replace = FALSE)\n\n# Training dataset\ndata_train <- data[ind,]\n# Testing dataset\ndata_test <- data[-c(ind),]\n\ndata |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    response            V8              V11              V15          \n Min.   :0.0000   Min.   : 0.000   Min.   : 0.000   Min.   :     0.0  \n 1st Qu.:0.0000   1st Qu.: 0.165   1st Qu.: 0.000   1st Qu.:     0.0  \n Median :0.0000   Median : 1.000   Median : 0.000   Median :     5.0  \n Mean   :0.4499   Mean   : 2.209   Mean   : 2.435   Mean   :  1021.2  \n 3rd Qu.:1.0000   3rd Qu.: 2.574   3rd Qu.: 3.000   3rd Qu.:   395.5  \n Max.   :1.0000   Max.   :28.500   Max.   :67.000   Max.   :100000.0  \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read the STAN file\nfile_stan <- \"logistic_regression.stan\"\n\n# Compile stan model\nmodel_stan <- cmdstan_model(stan_file = file_stan,\n                            cpp_options = list(stan_threads = TRUE))\nmodel_stan$check_syntax()\n```\n:::\n\n\n\n::: {style=\"text-align: justify\"}\nNow that the model is compiled, we will prepare the data to supply to the model to estimate the parameters based on the training data and make predictions on the testing data.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Get the data in appropriate form to pass to STAN model\nx_train <- data_train[,-1]\ny_train <- data_train[,1] \nx_test <- data_test[,-1]\ny_test <- data_test[,1]\n\nx_train <- x_train |> as.matrix()\nx_test <- x_test |> as.matrix()\n\nstandata <- list(K = ncol(x_train),\n                 N1 = nrow(x_train),\n                 X1 = x_train,\n                 Y1 = y_train,\n                 N2 = nrow(x_test),\n                 X2 = x_test,\n                 Y2 = y_test)\n\nfit_optim <- model_stan$optimize(data = standata,\n                                 seed = seed,\n                                 threads =  10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInitial log joint probability = -93090.2 \n    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes  \n      99      -257.751    0.00427413       40.0854           1           1      164    \n    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes  \n     105      -257.738    0.00103664      0.596166           1           1      171    \nOptimization terminated normally:  \n  Convergence detected: relative gradient magnitude is below tolerance \nFinished in  0.1 seconds.\n```\n\n\n:::\n\n```{.r .cell-code}\nfsum_optim <- as.data.frame(fit_optim$summary())\n\n# The optimized parameter would be \npar_ind <- 2:(ncol(x_train)+2)\nopt_pars <- fsum_optim[par_ind,]\nopt_pars\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  variable     estimate\n2    alpha -1.319880000\n3  beta[1]  0.224366000\n4  beta[2]  0.333478000\n5  beta[3]  0.000385548\n```\n\n\n:::\n\n```{.r .cell-code}\n# starting value of parameters\nstart_parameters <- rep(list(list(alpha = opt_pars[1,2],\n                                  beta = opt_pars[-1,2])),4)\n\n# Run the MCMC with optimized values as the starting values\nfit <- model_stan$sample(\n  data = standata,\n  init = start_parameters,\n  seed = seed,\n  iter_warmup = 10000,\n  iter_sampling = 10000,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 10000,\n  threads =  32,\n  save_warmup = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning MCMC with 4 parallel chains, with 32 thread(s) per chain...\n\nChain 1 Iteration:     1 / 20000 [  0%]  (Warmup) \nChain 2 Iteration:     1 / 20000 [  0%]  (Warmup) \nChain 3 Iteration:     1 / 20000 [  0%]  (Warmup) \nChain 4 Iteration:     1 / 20000 [  0%]  (Warmup) \nChain 2 Iteration: 10000 / 20000 [ 50%]  (Warmup) \nChain 2 Iteration: 10001 / 20000 [ 50%]  (Sampling) \nChain 1 Iteration: 10000 / 20000 [ 50%]  (Warmup) \nChain 1 Iteration: 10001 / 20000 [ 50%]  (Sampling) \nChain 3 Iteration: 10000 / 20000 [ 50%]  (Warmup) \nChain 3 Iteration: 10001 / 20000 [ 50%]  (Sampling) \nChain 4 Iteration: 10000 / 20000 [ 50%]  (Warmup) \nChain 4 Iteration: 10001 / 20000 [ 50%]  (Sampling) \nChain 2 Iteration: 20000 / 20000 [100%]  (Sampling) \nChain 2 finished in 22.2 seconds.\nChain 1 Iteration: 20000 / 20000 [100%]  (Sampling) \nChain 1 finished in 23.1 seconds.\nChain 3 Iteration: 20000 / 20000 [100%]  (Sampling) \nChain 3 finished in 24.0 seconds.\nChain 4 Iteration: 20000 / 20000 [100%]  (Sampling) \nChain 4 finished in 28.7 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 24.5 seconds.\nTotal execution time: 28.8 seconds.\n```\n\n\n:::\n\n```{.r .cell-code}\n# Summary\nfit$summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 175 × 10\n   variable       mean   median      sd     mad       q5      q95  rhat ess_bulk\n   <chr>         <dbl>    <dbl>   <dbl>   <dbl>    <dbl>    <dbl> <dbl>    <dbl>\n 1 lp__       -2.60e+2 -2.59e+2 1.41e+0 1.21e+0 -2.62e+2 -2.58e+2  1.00   14580.\n 2 alpha      -1.34e+0 -1.33e+0 1.48e-1 1.49e-1 -1.58e+0 -1.10e+0  1.00   15832.\n 3 beta[1]     2.28e-1  2.27e-1 4.57e-2 4.59e-2  1.55e-1  3.05e-1  1.00   16114.\n 4 beta[2]     3.40e-1  3.38e-1 5.22e-2 5.14e-2  2.56e-1  4.28e-1  1.00   17570.\n 5 beta[3]     4.08e-4  4.01e-4 1.19e-4 1.18e-4  2.25e-4  6.14e-4  1.00   38585.\n 6 Y2[1]       5.95e-1  5.95e-1 6.00e-2 6.01e-2  4.96e-1  6.94e-1  1.00   19639.\n 7 Y2[2]       3.64e-1  3.64e-1 2.51e-2 2.53e-2  3.24e-1  4.06e-1  1.00   23912.\n 8 Y2[3]       7.44e-1  7.45e-1 4.29e-2 4.30e-2  6.72e-1  8.14e-1  1.00   21883.\n 9 Y2[4]       4.08e-1  4.07e-1 2.97e-2 2.98e-2  3.60e-1  4.57e-1  1.00   27887.\n10 Y2[5]       9.41e-1  9.45e-1 2.62e-2 2.41e-2  8.92e-1  9.75e-1  1.00   19075.\n# ℹ 165 more rows\n# ℹ 1 more variable: ess_tail <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\n# Save the summary\nfsum <- as.data.frame(fit$summary())\n```\n:::\n\n\n\n\n::: {style=\"text-align: justify\"}\nNext we look at the posterior distribution of the parameters and the trace plots. The posterior distribution of the parameters are unimodel and the trace plots indicates a good mix. So no issues with convergence.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot posterior distribution of parameters\nbayesplot::color_scheme_set(\"gray\")\nbayesplot::mcmc_dens(fit$draws(c(\"alpha\",\"beta\")))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/diagnostics-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Trace plots\nbayesplot::color_scheme_set(\"brewer-Spectral\")\nbayesplot::mcmc_trace(fit$draws(c(\"alpha\",\"beta\")))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/diagnostics-2.png){width=672}\n:::\n:::\n\n\n\n::: {style=\"text-align: justify\"}\nNow we check the prediction. The STAN model calculates the posterior probability. If the probability is greater than 1, we predict the response to be 1 and 0 otherwise. Based on the predictions, we will generate the confusion matrix.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check the predictions\npred_ind <- (max(par_ind)+1):(max(par_ind)+length(y_test))\n# predicted probability\npred_prob <- fsum[pred_ind,2]\npred_outcome <- ifelse(pred_prob>0.5,1,0)\n\n# Generate the confusion matrix\nconf_matrix2 <- caret::confusionMatrix(as.factor(pred_outcome),as.factor(y_test))\nconf_matrix2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 100  21\n         1   9  40\n                                          \n               Accuracy : 0.8235          \n                 95% CI : (0.7578, 0.8777)\n    No Information Rate : 0.6412          \n    P-Value [Acc > NIR] : 1.358e-07       \n                                          \n                  Kappa : 0.5991          \n                                          \n Mcnemar's Test P-Value : 0.04461         \n                                          \n            Sensitivity : 0.9174          \n            Specificity : 0.6557          \n         Pos Pred Value : 0.8264          \n         Neg Pred Value : 0.8163          \n             Prevalence : 0.6412          \n         Detection Rate : 0.5882          \n   Detection Prevalence : 0.7118          \n      Balanced Accuracy : 0.7866          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n\n\n:::\n\n```{.r .cell-code}\n# Accuracy\naccuracy <- mean(pred_outcome == y_test)\nprint(paste('Accuracy is ',round(accuracy,4)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Accuracy is  0.8235\"\n```\n\n\n:::\n:::\n\n\n\n::: {style=\"text-align: justify\"}\nOur model has an accuracy of around 83% which indicates the model is correctly identifying the posiitve and negative cases in around 83% of the cases. Next, we look at the Receiver Operating Characteristic (ROC) curve. It plots the True Positive Rate (TPR) against the False Positive Rate (FPR). It is the visualization of trade-off between correctly identifying positive cases and incorrectly identifying negative cases as positive. A good model ROC curve which goes from bottom left to top left which means the model is perfectly identifying positive cases and does not identify negatives as positive. On the other hand, a ROC curve which is a straight line from bottom left to to right with slope 1 indicates the model is randomly assigning the positive and negative cases. Our curve is somewhere in between these 2 extreme cases and is decent. The area under the curve (AUC) is around 79% which is also decent.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ROC curve\nlibrary(ROCR)\npr <- prediction(pred_outcome, y_test)\nprf <- performance(pr, measure = \"tpr\", x.measure = \"fpr\")\nplot(prf)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/diagnostics3-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# AUC \nauc <- performance(pr, measure = \"auc\")\nauc <- auc@y.values[[1]]\nauc\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.7865844\n```\n\n\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}