---
title: "Predictive model for house price using Gaussian Process regression"
subtitle: "Gaussian Process regression for non linear relationship to predict house price"
author: "Aditya Ranade"
highlight-style:
            light: github
date: "2025-03-03"
categories: [analysis, R]
image: "./house_price.jpg"
---

::: {style="text-align: justify"}
Good houses are always in demand. However in the recent times, the price of house has increased exponentially. It will be interesting to identify the factors affecting the price of house. I found this [dataset](https://archive.ics.uci.edu/dataset/477/real+estate+valuation+data+set) on UCI machine learning repository which gives the house price per unit area and related variables.
:::

::: {style="text-align: justify"}
The idea is to build a predictive model to predict house price per unit area based on the variables like the age of house, etc. We will look at the exploratory data analysis first and later build prediction models. First let us access and process the data through R.
:::

```{r}
#| label: load-packages
#| echo: true
#| warning: false
#| include: true

# Load the packages
library(reshape2)
library(ggplot2)
library(ggh4x)
library(ggcorrplot)
library(car) # to calculate the VIF values
library(GGally) # for pairs plot using ggplot framework
```

```{r}
#| label: data_processing1
#| echo: true
#| warning: false
#| include: true

# Get starbucks data from github repo
path = "https://raw.githubusercontent.com/adityaranade/portfolio/refs/heads/main/real_estate/real_estate_valuation.csv"
data0 <- read.csv(path, header = TRUE)

# Data processing
# clean the column names
colnames(data0) <- c("ID", "date", "house_age", "distance", "number_store", "latitude", "longitude", "price")

# Check the first 6 rows of the dataset
data0 |> head()

```

::: {style="text-align: justify"}
We will focus on the 3 variables as follows

-   house_age : age of house in years.

-   distance : distance to nearest MRT station in meters.

-   number_store : the number of convenience stores in the living circle on foot.

-   price : Price per unit area where 1 unit is 1 ping = 3.3 sq. meter

Let us look at the distribution of these 3 variables
:::

```{r}
#| label: data_processing2
#| echo: true
#| warning: false
#| include: true

# Check the rows which do not have any entries
ind.na <- sum(is.na(data0))
ind.na # No NA values

# Filter the data
# column house_age, distance and price
# data <- data0 |> select(c(house_age,distance,price))
data <- data0[,c("house_age","distance","number_store","price")]
data |> head()

# Data for histogram
melted_data <- melt(data)

# Plot the histogram of all the variables
ggplot(melted_data,aes(value))+
  geom_histogram(bins = 20)+
  # geom_histogram(aes(y = after_stat(density)),bins = 20)+
  facet_grid2(~variable, scales="free")+theme_bw()
```

::: {style="text-align: justify"}
Histogram does not give much information. Let us look at the correlation plot to get an idea of how the variables are correlated with each other.
:::

```{r}
#| label: correlation_plot
#| echo: true
#| warning: false
#| include: true

# correlation plot of all the variables
corr <- round(cor(data), 2)
ggcorrplot(corr)
```

::: {style="text-align: justify"}
house_age is not related to distance and number_store which is not surprising. distance variable is positively correlated with number of stores which again not surprising. However price is negatively correlated with distance to nearest MRT station as well as house age and positively correlated with number of stores in the vicinity which is again logical. Next we look at the pairs plot which will show the bivariate scatter plots as well as the correlation between each variables. Scatter plots in the last row is of interest as it shows the pairwise scatterplots where price is on the y axis and the other variables are on the x axis.
:::

```{r}
#| label: pairplots
#| echo: true
#| warning: false
#| include: true

ggpairs(data)

```

::: {style="text-align: justify"}
The scatterplot of price vs. distance does not look linear but more of curved. We will focus on predicting price based on the distance variable. We will look at a simple linear regression where we will try to predict price as a function of distance.
:::

```{r}
#| label: SLR
#| echo: true
#| warning: false
#| include: true

# split the data into training and testing data
seed <- 23
set.seed(seed)

ind <- sample(floor(0.75*nrow(data)),
              replace = FALSE)

# Training dataset
data_train <- data[ind,]
# Testing dataset
data_test <- data[-ind,]

# Simple linear regression using raw data
model <- lm(price ~ distance, data = data_train)
summary(model)

# Prediction on the testing dataset
y_pred <- predict(model, data_test)

# Calculate residuals = observed - predicted
residuals <- (data_test$price - y_pred)

# Residual vs. predicted plot
ggplot(NULL,aes(y_pred,residuals))+geom_point()+
  labs(y = "Residuals", x="Predicted price")+ 
  geom_hline(yintercept = 0, colour = "red")

```

::: {style="text-align: justify"}
The residual plot shows a trumpet horn pattern which indicates the constant variance assumption of the model is not satisfied. Hence out model is not reliable. This is not surprising since the scatterplot indicates a curved fit rather than a linear fit.
:::

```{r}
#| label: SLR_checks
#| echo: true
#| warning: false
#| include: true

# Create a observed vs. predicted plot
ggplot(NULL,aes(y_pred,data_test$price))+geom_point()+
  labs(y = "Observed", x="Predicted")+
  lims(x=c(0,80),y=c(0,80))+
  geom_abline()

# Calculate RMSE
rmse <- (residuals)^2 |> sum() |> sqrt()
round(rmse,2)

# Check the assumptions of the regression model
par(mfrow = c(2, 2))
plot(model)
```

::: {style="text-align: justify"}
The model is has RMSE = 92.69 and the observed vs. predicted plot has the trumpet horm pattern so it is not good model. We will now look at a Gaussian process model which can handle non linear relationships very well.
:::
