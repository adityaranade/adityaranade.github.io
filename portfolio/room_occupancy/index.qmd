---
title: "Office Room Occupancy"
subtitle: "Predicting office room occupancy using binary logistic regression model"
author: "Aditya Ranade"
highlight-style:
            light: github
date: "2025-04-19"
categories: [analysis, R]
image: "./occupancy.jpg"
---

::: {style="text-align: justify"}
I found this [dataset](https://archive.ics.uci.edu/dataset/357/occupancy+detection) on UCI machine learning repository which gives the dataset for predicting the room occupancy in office using variables like temperature, humidity, light, carbon-dioxide and humidity ratio. Since the variable of interest is room occupancy, it is binary variable being occupied or not occupied. We will build a logistic regression model to predict the room occupancy using the information. First let us look at the data.
:::

```{r}
#| label: load-packages
#| echo: true
#| warning: false
#| include: true

library(reshape2)
library(ggplot2)
library(dplyr)
library(ggh4x)
library(GGally)
library(pROC)
library(glmnet)
library(caret)

# Get data from github repo
path <- "https://raw.githubusercontent.com/adityaranade/portfolio/refs/heads/main/occupancy/occupancy_data.txt"
data0 <- read.table(path, sep=",", header = TRUE)

# Data processing
# Check the type of data
data0 |> str()

# Check the rows which do not have any entries
sum(is.na(data0)) # No NA values

# Check the first 6 rows of the dataset
data0%>% head

```

::: {style="text-align: justify"}
First column is the date which we will ignore. There are no missing values. Occupancy is the binary variable which takes value 0 if the room is not occupied and takes the value 1 if the room is occupied. The explanatory variables are temperature, humidity, light carbon dioxide (CO2) and humidity ratio which are all numerical variables. Next, we will look at the correlation plot which shows the correlation between each pair of the explanatory variables.
:::

```{r}
#| label: EDA1
#| echo: true
#| warning: false
#| include: true
#| fig-width: 20
#| fig-height: 10

# pairs plot for correlation between every pair of correlation
ggpairs(data0[,-c(1,3,ncol(data0))]) # exclude the date and binary variable

```

::: {style="text-align: justify"}
Humidity and Humidity ratio has high correlation (close to 1). This is on expected lines as humidity ratio is derived from humidity. Now let us look at the distribution of the continuous variables according to occupancy variable.
:::

```{r}
#| label: EDA2
#| echo: true
#| warning: false
#| include: true
#| fig-width: 20
#| fig-height: 10

# Data for histogram
melted_data <- melt(na.omit(data0[,-c(1)]), id="Occupancy")

# Plot the histogram of all the variables
ggplot(melted_data,aes(value))+
  geom_histogram(aes(),bins = 30)+
  facet_grid2(Occupancy~variable, scales="free")+theme_bw()
```

::: {style="text-align: justify"}
We will keep temperature and light in the model as explanatory variable and look to predict the room occupancy using a logistic regression model.
:::

```{r}
#| label: data processing
#| echo: true
#| warning: false
#| include: true

# Select the variables to keep in the model
data <- data0 |> select(c(Light,HumidityRatio,Occupancy))

# split the data into training and testing data
seed <- 23
set.seed(seed)
ind <- sample(floor(0.75*nrow(data)),
              replace = FALSE)

# Training dataset
data_train <- data[ind,]

# Testing dataset
data_test <- data[-c(ind),]

```

```{r}
#| label: base_model0
#| echo: true
#| warning: false
#| include: true

# Fit a logistic regression model
model <- glm(Occupancy ~ ., data = data_train, family = "binomial") 

# Check the summary of the model
model |> summary()

# Prediction probability on the testing dataset
y_pred_prob <- predict(model, data_test, type = "response")

# Prediction class on the testing dataset
y_pred <- ifelse(y_pred_prob>0.5,1,0)

# confusion matrix
conf_table <- table(data_test$Occupancy,y_pred)
confusionMatrix(conf_table)
```

::: {style="text-align: justify"}
The misclassification is 8 out of a total of 2036 test cases which is not a bad situation.
:::

```{r}
#| label: base_model1
#| echo: true
#| warning: false
#| include: true

# Misclassification
1 - sum(diag(conf_table)) / sum(conf_table)

# Compute ROC curve
roc_curve <- roc(data_test$Occupancy,as.vector(y_pred_prob))

# Calculate AUC
auc_value <- auc(roc_curve)

# Plot the ROC curve
plot(roc_curve, col = "blue", lwd = 3, main = "ROC Curve")

# Add AUC to the plot
legend("bottomright", legend = paste("AUC =", round(auc_value, 3)), col = "blue", lwd = 3)
```

::: {style="text-align: justify"}
Misclassification is just around 0.4% on the testing dataset. This is not bad. Also the ROC curve is close to perfect and Area under the curve is also close to 1.
:::
