---
title: "Predicting car price"
subtitle: "AI models to predict car price using car features"
author: "Aditya Ranade"
highlight-style:
  light: github
date: "2025-05-15"
categories: [analysis, R]
image: "./car.jpg"
---

::: {style="text-align: justify"}
I found this [dataset](https://archive.ics.uci.edu/dataset/10/automobile) on UCI machine learning repository which gives the dataset regarding the car features along with price. The goal is to predict the car price indicated by the variable price based on other features of the car like horespower, displacement, weight, etc. of car. We will compare multiple Machine Learning models for the same.
:::

```{r}
#| label: load-packages
#| echo: true
#| warning: false
#| include: true

library(reshape2)
library(ggplot2)
library(ggh4x)
library(ggcorrplot)
library(GGally) # for pairs plot using ggplot framework
library(dplyr)
library(glmnet)
library(knitr)

# Get cars data from github repo
path <- "https://raw.githubusercontent.com/adityaranade/portfolio/refs/heads/main/car_price/automobile.data"
data0 <- read.table(path, 
                    sep = ",", 
                    fill = TRUE, 
                    header = FALSE)

colnames(data0) <- c( "symbolling", "normalized_losses", "make", "fuel_type", 
                      "aspiration", "doors","body_style", "drive_wheels", 
                      "engine_location", "wheel_base","length", "width", 
                      "height", "curb_weight", "engine_type", "cylinders", 
                      "engine_size", "fuel_system", "bore", "stroke", 
                      "compression_ratio", "horsepower", "peak_rpm", 
                      "city_mpg", "highway_mpg", "price")

# Check the type of data
data0 |> str()

# Convert the specific data types to numeric
data0$bore <- as.numeric(data0$bore)
data0$stroke <- as.numeric(data0$stroke)
data0$horsepower <- as.numeric(data0$horsepower)
data0$peak_rpm <- as.numeric(data0$peak_rpm)
data0$price <- as.numeric(data0$price)

# Check the type of data again
data0 |> str()

# Check the rows which do not have any entries
sum(is.na(data0)) # 16 NA values

# Exclude the rows with missing information
data1 <- na.omit(data0)

# Check NA values again
sum(is.na(data1)) # No NA values

# Check the first 6 rows of the dataset
data1 |> head()
```

```{r}
#| label: EDA01
#| echo: true
#| warning: false
#| include: true
#| fig-width: 14
#| fig-height: 16

# Select the numerical columns and then draw a pairs plot
# Pairs plot between the explanatory variables to 
# check correlation between each pair of the variables
data1 |> select(where(is.numeric)) |> ggpairs()
```

::: {style="text-align: justify"}
The response variable, price is correlated with all the variables which is good. However, the explanatory variables are correlated within themselves which is not a good indication. This indicates there is some multicollinearity. This means two variables give similar information about the response variable. One way to mitigate the effect is to consider the principal components and then use the principal components for the models. Another way is to use some regularization to mitigate the effect of multicollinearity.
:::

```{r}
#| label: EDA02
#| echo: true
#| warning: false
#| include: true
#| fig-width: 14

# Histogram of price variable
ggplot(data1,aes(x=price))+
  geom_histogram(aes(y = after_stat(density)),bins = 30)+
  labs(title = "Distribution of Prices", 
       x = "price", y = "Density")

# log scale
ggplot(data1, aes(x = price)) + 
  geom_histogram(aes(y = after_stat(density)),bins = 30) +
  labs(title = "Log-Scale Distribution of Prices", 
       x = "log(price)", y = "Density") +
  scale_x_log10()
```

```{r}
#| label: EDA03
#| echo: true
#| warning: false
#| include: true
#| fig-width: 14
#| fig-height: 20

# Histogram of price according to make
ggplot(data1, aes(x = price, y = make)) + 
  geom_boxplot(fill="skyblue", col="black") +
  labs(title = "Price Distribution by Make", 
       x = "Make", y = "Price") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}
#| label: data_split
#| echo: true
#| warning: false
#| include: true

# Select specific columns for the ML model

data2 <- subset(data1, select = c(wheel_base,length,width,curb_weight,
                                 engine_size, bore,
                                 stroke,compression_ratio,horsepower,
                                 peak_rpm,city_mpg,highway_mpg,price))

# data2 <- data1 |> select(wheel_base,length,width,curb_weight,
#                         #fuel_type,cylinders,
#                         engine_size,bore, stroke,
#                         compression_ratio,horsepower,
#                         peak_rpm,city_mpg,highway_mpg,price)

# split the data into training and testing data
seed <- 55
set.seed(seed)

ind <- sample(1:nrow(data2),
              floor(0.8*nrow(data2)),
              replace = FALSE)

# Training dataset
data_train <- data2[ind,]
# Testing dataset
data_test <- data2[-ind,]
```

```{r}
#| label: mlr
#| echo: true
#| warning: false
#| include: true

# Fit a linear regression model
# Fit a multiple linear regression model
model_lm <- glm(price ~ ., data = data_train)

# Check the summary of the model
model_lm |> summary()

# Predictions on test data
y_pred_lm <- predict(model_lm, data_test)

# data frame for plotting
df_pred_mlr <- data.frame(predicted = y_pred_lm, 
                    observed = data_test$price)
df_pred_mlr$model <- "mlr"

# evaluation metrics
rmse_lm <- (data_test$price-y_pred_lm)^2 |> mean() |> sqrt()
mae_lm <- (data_test$price-y_pred_lm) |> abs() |> mean()
```

```{r}
#| label: ridge
#| echo: true
#| warning: false
#| include: true

library(glmnet)
# Ensure all factor variables in test have the same levels as training
for (col in names(data_train)) {
  if (is.factor(data_train[[col]])) {
    data_test[[col]] <- factor(data_test[[col]], levels = levels(data_train[[col]]))
  }
}

# Now build matrices
X  <- model.matrix(price ~ . - 1, data = data_train)
y  <- data_train$price
X.new <- model.matrix(price ~ . - 1, data = data_test)

model_l2_cv <- cv.glmnet(X,y,alpha = 0)

#find optimal lambda value that minimizes test MSE
best_lambda <- model_l2_cv$lambda.min

model_l2 <- glmnet(X,y,
                   alpha = 1,
                   lambda = best_lambda)
#coef(model_l2)

# for predictions
X.new <- model.matrix(price ~ . - 1,
                      data = data_test)

# Predictions on test data
y_pred_l2 <- predict(model_l2,
                     s = best_lambda,
                     newx= X.new)

# data frame for plotting
df_pred_l2 <- data.frame(predicted = as.vector(y_pred_l2),
                         observed = data_test$price)
df_pred_l2$model <- "ridge"

# evaluation metrics 
rmse_l2 <- (data_test$price-y_pred_l2)^2 |> mean() |> sqrt()
mae_l2 <- (data_test$price-y_pred_l2) |> abs() |> mean()
```

```{r}
#| label: lasso
#| echo: true
#| warning: false
#| include: true

model_l1_cv <- cv.glmnet(as.matrix(data_train[,-ncol(data_train)]),
                         as.matrix(data_train[,ncol(data_train)]),
                         alpha = 0)

#find optimal lambda value that minimizes test MSE
best_lambda_l1 <- model_l1_cv$lambda.min
best_lambda_l1

model_l1 <- glmnet(as.matrix(data_train[,-ncol(data_train)]),
                   as.matrix(data_train[,ncol(data_train)]),
                   alpha = 0,
                   lambda = best_lambda_l1)
#coef(model_l1)

# Predictions on test data
y_pred_l1 <- predict(model_l1,  s = best_lambda_l1,
                     newx= as.matrix(data_test[,-ncol(data_train)]))

# data frame for plotting
df_pred_l1 <- data.frame(predicted = as.vector(y_pred_l1),
                         observed = data_test$price)
df_pred_l1$model <- "ridge"

# evaluation metrics
rmse_l1 <- (data_test$price-y_pred_l1)^2 |> mean() |> sqrt()
mae_l1 <- (data_test$price-y_pred_l1) |> abs() |> mean()
```

```{r}
#| label: elastic_net
#| echo: true
#| warning: false
#| include: true

# Elastic net
model_en_cv <- cv.glmnet(as.matrix(data_train[,-ncol(data_train)]),
                         as.matrix(data_train[,ncol(data_train)]),
                         alpha = 0.5)

#find optimal lambda value that minimizes test MSE
best_lambda_en <- model_en_cv$lambda.min


model_en <- glmnet(as.matrix(data_train[,-ncol(data_train)]),
                   as.matrix(data_train[,ncol(data_train)]),
                   alpha = 0.5,
                   lambda = best_lambda_en)
#coef(model_en)

# Predictions on test data
y_pred_en <- predict(model_en,  s = best_lambda_en,
                     newx= as.matrix(data_test[,-ncol(data_train)]))

# data frame for plotting
df_pred_en <- data.frame(predicted = as.vector(y_pred_en),
                    observed = data_test$price)
df_pred_en$model <- "elastic_net"

# evaluation metrics
rmse_en <- (data_test$price-y_pred_en)^2 |> mean() |> sqrt()
mae_en <- (data_test$price-y_pred_en) |> abs() |> mean()
```

```{r}
#| label: tree
#| echo: true
#| warning: false
#| include: true

# Tree approach
library(rpart)
library(rpart.plot)

# Fit regression tree
model_tree <- rpart(price ~ ., data = data_train, method = "anova")

# Summary
summary(model_tree)

# control complexity of tree
printcp(model_tree) # shows cross-validated error by cp
best_cp <- model_tree$cptable[which.min(model_tree$cptable[,"xerror"]), "CP"]

# Plot
model_tree_pruned <- prune(model_tree, cp = best_cp)
rpart.plot(model_tree_pruned, type = 3, extra = 101)

# Predictions on test data
y_pred_tree <- predict(model_tree, data_test)

# data frame for plotting
df_pred_tree <- data.frame(predicted = y_pred_tree, 
                    observed = data_test$price)
df_pred_tree$model <- "tree"

# evaluation metrics
rmse_tree <- (data_test$price-y_pred_tree)^2 |> mean() |> sqrt()
mae_tree <- (data_test$price-y_pred_tree) |> abs() |> mean()
```

```{r}
#| label: random_forest
#| echo: true
#| warning: false
#| include: true

# Random forest
library(randomForest)
model_rf <- randomForest(price ~ ., data = data_train)
predict(model_rf, data_test)

# Predictions on test data
y_pred_rf <- predict(model_rf, data_test)

# data frame for plotting
df_pred_rf <- data.frame(predicted = y_pred_rf, 
                      observed = data_test$price)
df_pred_rf$model <- "random_forest"

# evaluation metrics
rmse_rf <- (data_test$price-y_pred_rf)^2 |> mean() |> sqrt()
mae_rf <- (data_test$price-y_pred_rf) |> abs() |> mean()
```

```{r}
#| label: svm
#| echo: true
#| warning: false
#| include: true

# SVM
library(e1071)
model_svm <- svm(price ~ ., data = data_train, 
                 kernel = "radial", cost = 10, 
                 gamma = 0.1)

# Predictions on test data
y_pred_svm <- predict(model_svm, data_test)

# data frame for plotting
df_pred_svm <- data.frame(predicted = y_pred_svm, 
                          observed = data_test$price)
df_pred_svm$model <- "svm"

# evaluation metrics
rmse_svm <- (data_test$price-y_pred_svm)^2 |> mean() |> sqrt()
mae_svm <- (data_test$price-y_pred_svm) |> abs() |> mean()
```

```{r}
#| label: metrics
#| echo: true
#| warning: false
#| include: true
#| fig-width: 14

# Plot observed vs. predicted for all the models
df_pred <- rbind(df_pred_mlr, df_pred_tree, 
                 df_pred_l1,df_pred_l2,df_pred_en,
                 df_pred_rf, df_pred_svm)

# Create a observed vs. predicted plot combined for all the models
ggplot(df_pred,aes(predicted,observed))+geom_point()+
  lims(x = c(10000,50000) , y = c(10000,50000))+
  labs(y = "Observed", x="Predicted")+
  facet_grid(~model, scales="free")+
  geom_abline()+
  theme_bw(base_size = 15)


# Evaluation metrics for all the models
metrics_all <- data.frame(Model = c("linear_model", "lasso", "ridge",
                                    "elastic_net", "tree", "random_forest",
                                    "svm"),
                          RMSE = c(rmse_lm,rmse_l1, rmse_l2, rmse_en,
                                   rmse_tree, rmse_rf, rmse_svm),
                          MAE = c(mae_lm,mae_l1, mae_l2, mae_en,
                                  mae_tree, mae_rf, mae_svm))

# Print evaluation metrics
kable(metrics_all, digits = 0, caption = "Model Performance Metrics")
```

```{r}
#| label: metrics2
#| echo: true
#| warning: false
#| include: true
#| fig-width: 14

metrics_long <- melt(metrics_all, id.vars = "Model",
                     variable.name = "Metric",
                     value.name = "Value")

# To plot RMSE and MAE side by side
ggplot(metrics_long, aes(x = Model, y = Value, fill = Model)) +
  geom_col(show.legend = FALSE) +
  geom_text(aes(label = round(Value)), 
            position = position_dodge(width = 0.5),
            hjust = 1.25, size = 3) +
  coord_flip(clip = "off") +  # horizontal bars, no clipping of text
  facet_grid2(~Metric, scales="free")+
  labs(title = "Model Performance Comparison", 
       y = "Error Value", x = "Model") +
  theme_bw(base_size = 15) +
  theme(plot.title = element_text(face = "bold", hjust = 0.5))


# # To plot RMSE and MAE on the same plot
# ggplot(metrics_long, aes(x = Model, y = Value, fill = Metric)) +
#   geom_col(position = position_dodge(width = 0.8)) +
#   geom_text(aes(label = round(Value, 2)),
#             position = position_dodge(width = 0.8),
#             vjust = -0.3, size = 3) +
#   labs(title = "Model Performance Comparison",
#        y = "Error Value", x = "Model") +
#   theme_bw(base_size = 10) +
#   theme(plot.title = element_text(face = "bold", hjust = 0.5))

```

::: {style="text-align: justify"}
Based on the metrics, random forest model seems to be the best model.
:::
