{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Predicting Gallstone Disease\"\n",
        "subtitle: \"Comparing AI methods to predict gallstone disease\"\n",
        "author: \"Aditya Ranade\"\n",
        "highlight-style: github-light\n",
        "date: \"2025-05-07\"\n",
        "categories: [analysis, python, R]\n",
        "image: \"./gallbladder.png\"\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "\n",
        "::: {style=\"text-align: justify\"}\n",
        "I found this [dataset](https://archive.ics.uci.edu/dataset/1150/gallstone-1) on Kaggle which gives gallstone disease identification data. First, we look at the exploratory data analysis and later try to build predictive models like logistic regression, support vector classifier and k nearest neighbour model. First let us access and process the data through python\n",
        ":::\n"
      ],
      "id": "ac7ace16"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: load-packages\n",
        "#| echo: true\n",
        "#| warning: false\n",
        "#| include: true\n",
        "\n",
        "# Load Libraries\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from plotnine import *\n",
        "import numpy as np # linear algebra\n",
        "# import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import openpyxl\n",
        "\n",
        "# Get gallstone data from github repo\n",
        "path = \"https://raw.githubusercontent.com/adityaranade/portfolio/refs/heads/main/gallstone/gallstone_dataset.csv\"\n",
        "df0=pd.read_csv(path)\n",
        "\n",
        "df0.head()"
      ],
      "id": "load-packages",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: data_processing1\n",
        "#| echo: true\n",
        "#| warning: false\n",
        "#| include: true\n",
        "\n",
        "# select specific columns\n",
        "df = df0[[\"Gallstone Status\",\"Vitamin D\",\"Total Body Water (TBW)\",\"Lean Mass (LM) (%)\",\"C-Reactive Protein (CRP)\"]]\n",
        "# df.head()"
      ],
      "id": "data_processing1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: data_processing2\n",
        "#| echo: true\n",
        "#| warning: false\n",
        "#| include: true\n",
        "\n",
        "# Use melt function for the histograms\n",
        "df2 = pd.melt(df, id_vars=['Gallstone Status'])\n",
        "# df2.head()"
      ],
      "id": "data_processing2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {style=\"text-align: justify\"}\n",
        "Now that we have the data ready, let us look at the histogram of each variables namely calories, fat, carbs, fiber, protein and sodium\n",
        ":::\n"
      ],
      "id": "85f116c0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: EDA\n",
        "#| echo: true\n",
        "#| warning: false\n",
        "#| include: true\n",
        "\n",
        "p = (\n",
        "ggplot(df2, aes(\"value\"))\n",
        "+ geom_histogram(bins=20)\n",
        "+ facet_grid(\"Gallstone Status ~ variable\", scales=\"free\")+\n",
        "  theme_bw()\n",
        ")\n",
        "\n",
        "p.show()"
      ],
      "id": "EDA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The histogram of each of the variables do not show any problems as all the plots look decent. We will look at the correlation plot.\n"
      ],
      "id": "73fedbb9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: EDA2\n",
        "#| echo: true\n",
        "#| warning: false\n",
        "#| include: true\n",
        "\n",
        "# Correlation plot\n",
        "plt.figure(figsize=(20,8))\n",
        "sns.heatmap(df.iloc[:,1:].corr(),annot=True)\n",
        "plt.show()"
      ],
      "id": "EDA2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {style=\"text-align: justify\"}\n",
        "Correlation plot indicates weak association between all the variables which indicates there might not be severe multicolinearity. It does not warrant any cause of concern. Now we will look at the pairs plot which will show the pairwise relationship.\n",
        ":::\n"
      ],
      "id": "14a50e67"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: EDA3\n",
        "#| echo: true\n",
        "#| warning: false\n",
        "#| include: true\n",
        "\n",
        "# Pairs plot\n",
        "g = sns.PairGrid(df.iloc[:,1:])\n",
        "g.map_diag(sns.histplot)\n",
        "g.map_upper(sns.kdeplot)\n",
        "g.map_lower(sns.scatterplot)\n",
        "plt.show()"
      ],
      "id": "EDA3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {style=\"text-align: justify\"}\n",
        "The scatterplots of each variable with which can be seen in the lower triangular plots. No strong association between any two variables. We will try to run different models like logistic regression, k nearest neighbours and support vector classification model on the data. First we will split the data into training (70%) and testing set (30%) and standardize the data.\n",
        ":::\n"
      ],
      "id": "ab472e8b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: data_split\n",
        "#| echo: true\n",
        "#| warning: false\n",
        "#| include: true\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Split data into training and testing set\n",
        "df_train0, df_test0 = train_test_split(df, test_size=0.3, random_state=23)\n",
        "\n",
        "# Scale (exclude first column)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "df_train = df_train0.copy()\n",
        "df_test = df_test0.copy()\n",
        "\n",
        "df_train.iloc[:, 1:] = scaler.fit_transform(df_train0.iloc[:, 1:])\n",
        "df_test.iloc[:, 1:] = scaler.transform(df_test0.iloc[:, 1:])\n",
        "\n",
        "X_train = df_train.iloc[:,1:]\n",
        "y_train = df_train.iloc[:,0]\n",
        "X_test = df_test.iloc[:,1:]\n",
        "y_test = df_test.iloc[:,0]"
      ],
      "id": "data_split",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {style=\"text-align: justify\"}\n",
        "Now we will run a logistic regression model first.\n",
        ":::\n"
      ],
      "id": "f965219e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: logistic_model\n",
        "#| echo: true\n",
        "#| warning: false\n",
        "#| include: true\n",
        "\n",
        "# Create logistic regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "id": "logistic_model",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {style=\"text-align: justify\"}\n",
        "Next, we will run a k nearest neighbour model.\n",
        ":::\n"
      ],
      "id": "ce3a21d3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: knn_model\n",
        "#| echo: true\n",
        "#| warning: false\n",
        "#| include: true\n",
        "\n",
        "# KNN model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "k_values = range(1, 11)\n",
        "scores = []\n",
        "\n",
        "for k in k_values:\n",
        "  knn = KNeighborsClassifier(n_neighbors=k)\n",
        "  score = cross_val_score(knn, X_train, y_train, cv=5).mean()\n",
        "  scores.append(score)\n",
        "\n",
        "best_k = k_values[np.argmax(scores)]\n",
        "print(\"Best k:\", best_k)\n",
        "\n",
        "# Create KNN model using the best k\n",
        "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "id": "knn_model",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {style=\"text-align: justify\"}\n",
        "Next, we will run a support vector classification model.\n",
        ":::\n"
      ],
      "id": "bf3f01d7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: svc_model\n",
        "#| echo: true\n",
        "#| warning: false\n",
        "#| include: true\n",
        "\n",
        "# svc model\n",
        "from sklearn.svm import SVC\n",
        "# Identify the best parameter through CV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "'C': [0.1, 1, 10],\n",
        "'gamma': ['scale', 0.01, 0.1, 1],\n",
        "'kernel': ['rbf', 'linear']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(SVC(), param_grid, refit=True, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "\n",
        "# Create SVM model using the best parameters\n",
        "svm_model = SVC(kernel='rbf', C=10, gamma=0.01)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "id": "svc_model",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {style=\"text-align: justify\"}\n",
        "The R code for the analysis can be found [here](https://raw.githubusercontent.com/adityaranade/portfolio/refs/heads/main/gallstone/gallstone.R) \n",
        ":::"
      ],
      "id": "eabac0cc"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}